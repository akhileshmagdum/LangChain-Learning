{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efa911dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'D:/personal-git')\n",
    "from key_api import apiKey\n",
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = apiKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8810c4",
   "metadata": {},
   "source": [
    "# Schema\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391abdb2",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2e269ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Hi, What is captial of Maharashtra?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef60224",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e497ed77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You should explore the charming Old Town and indulge in delicious French cuisine.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=.7)\n",
    "\n",
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
    "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
    "        AIMessage(content=\"You should go to Nice, France\"),\n",
    "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f79acc",
   "metadata": {},
   "source": [
    "## Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b89bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\", metadata={'my_document_id': 234234, 'my_document_source': 'The LangChain Papers', 'my_document_create_time': 1680013019})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
    "         metadata={\n",
    "             'my_document_id' : 234234,\n",
    "             'my_document_source' : \"The LangChain Papers\",\n",
    "             'my_document_create_time' : 1680013019\n",
    "         })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dec896",
   "metadata": {},
   "source": [
    "# Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50666dab",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb554725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSaturday.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-ada-001\")\n",
    "llm(\"What day comes after Friday?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42db5e4",
   "metadata": {},
   "source": [
    "## Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6058dfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't you just teleport there? It's the fastest and most convenient way! Just make sure you have the right coordinates handy.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=1)\n",
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are an unhelpful AI bot that makes a joke at whatever the user says\"),\n",
    "        HumanMessage(content=\"I would like to go to New York, how should I do this?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc8d41",
   "metadata": {},
   "source": [
    "## Text Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76d86f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your embedding is length 1536\n",
      "Here's a sample: [-0.00011466221621958539, -0.0031506523955613375, -0.0007831145194359124, -0.019504327327013016, -0.015125557780265808]...\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "text = \"Hi! It's time for the beach\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "\n",
    "print (f\"Your embedding is length {len(text_embedding)}\")\n",
    "print (f\"Here's a sample: {text_embedding[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9502c078",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67fa6b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTuesday is missing.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Today is Monday, tomorrow is Wednesday.\n",
    "\n",
    "What is wrong with that statement?\n",
    "\"\"\"\n",
    "\n",
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25f682",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f55de092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prompt: \n",
      "I really want to travel to Rome. What should I do there?\n",
      "\n",
      "Respond in one short sentence\n",
      "\n",
      "-----------\n",
      "LLM Output: Visit the Colosseum, the Roman Forum, and the Trevi Fountain.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "template = \"\"\"\n",
    "I really want to travel to {location}. What should I do there?\n",
    "\n",
    "Respond in one short sentence\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"location\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(location='Rome')\n",
    "\n",
    "print (f\"Final Prompt: {final_prompt}\")\n",
    "print (\"-----------\")\n",
    "print (f\"LLM Output: {llm(final_prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b0ef7",
   "metadata": {},
   "source": [
    "## Example Selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60bd4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Example Input: {input}\\nExample Output: {output}\",\n",
    ")\n",
    "\n",
    "#Examples of locations that nouns are found\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
    "    {\"input\": \"pilot\", \"output\": \"plane\"},\n",
    "    {\"input\": \"driver\", \"output\": \"car\"},\n",
    "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
    "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62b732b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SemanticSimilarityExampleSelector will select examples that are similar to your input by semantic meaning\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    #This is the list of examples available to select from.\n",
    "    examples, \n",
    "    #This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(), \n",
    "    #This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS, \n",
    "    #This is the number of examples to produce.\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae0b8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt = FewShotPromptTemplate(\n",
    "    #The object that will help select examples\n",
    "    example_selector=example_selector,\n",
    "    #Your prompt\n",
    "    example_prompt=example_prompt,\n",
    "    #Customizations that will be added to the top and bottom of your prompt\n",
    "    prefix=\"Give the location an item is usually found in\",\n",
    "    suffix=\"Input: {noun}\\nOutput:\",\n",
    "    #What inputs your prompt will receive\n",
    "    input_variables=[\"noun\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b1be8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the location an item is usually found in\n",
      "\n",
      "Example Input: driver\n",
      "Example Output: car\n",
      "\n",
      "Example Input: pilot\n",
      "Example Output: plane\n",
      "\n",
      "Input: student\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "my_noun = \"student\"\n",
    "print(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "517ba6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' classroom'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f31a8c",
   "metadata": {},
   "source": [
    "# Output Parser\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe00976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b66277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#How you would like your response structured. Basically a fancy prompt template\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]\n",
    "\n",
    "#How you would like to parse your output\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "#See the prompt template you created for formatting\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print (format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750df8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a poorly formatted string from a user.\n",
      "Reformat it and make sure all the words are spelled correctly\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n",
      "\n",
      "% USER INPUT:\n",
      "welcom to califonya!\n",
      "\n",
      "YOUR RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT:\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "promptValue = prompt.format(user_input=\"welcom to califonya!\")\n",
    "\n",
    "print(promptValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce0c527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n\\t\"bad_string\": \"welcom to califonya!\",\\n\\t\"good_string\": \"Welcome to California!\"\\n}\\n```'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_output = llm(promptValue)\n",
    "llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070c9b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad_string': 'welcom to califonya!', 'good_string': 'Welcome to California!'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f50160",
   "metadata": {},
   "source": [
    "# Indexes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768c4c6",
   "metadata": {},
   "source": [
    "## Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b178d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (5.1.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: msg-parser in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (3.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (2.0.3)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (1.16.3)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (20221105)\n",
      "Requirement already satisfied: pillow in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (10.0.0)\n",
      "Requirement already satisfied: pypandoc in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (1.11)\n",
      "Requirement already satisfied: python-docx in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (0.8.11)\n",
      "Requirement already satisfied: python-pptx in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (0.6.21)\n",
      "Requirement already satisfied: python-magic in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: markdown in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (3.4.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: xlrd in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (2.0.1)\n",
      "Requirement already satisfied: olefile>=0.46 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from msg-parser->unstructured) (0.46)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->unstructured) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->unstructured) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->unstructured) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->unstructured) (4.65.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openpyxl->unstructured) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->unstructured) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->unstructured) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->unstructured) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->unstructured) (1.25.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six->unstructured) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six->unstructured) (41.0.2)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-pptx->unstructured) (3.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->unstructured) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->unstructured) (2023.5.7)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->unstructured) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk->unstructured) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99a7d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('d:/personal-git/Langchain-Learning',glob='dummy-data.txt')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "289ddeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 comments\n",
      "Here's a sample:\n",
      "\n",
      "Java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible. It is\n"
     ]
    }
   ],
   "source": [
    "print (f\"Found {len(docs)} comments\")\n",
    "print (f\"Here's a sample:\\n\\n{''.join([x.page_content[:150] for x in docs[:2]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735e005",
   "metadata": {},
   "source": [
    "## Text Splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "770cf3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open('d:/personal-git/Langchain-Learning/dummy-data.txt') as f:\n",
    "    pg_work = f.read()    \n",
    "print (f\"You have {len([pg_work])} document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cff31864",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap  = 20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([pg_work])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e315292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 301 documents \n",
      "\n",
      "PREVIEW::\n",
      "Java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible. It is \n",
      "\n",
      "as possible. It is a general-purpose programming language intended to let programmers write once, run anywhere (WORA),[17] meaning that compiled Java\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents \\n\")\n",
    "print (\"PREVIEW::\")\n",
    "print (texts[0].page_content, \"\\n\")\n",
    "print (texts[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b035e8",
   "metadata": {},
   "source": [
    "## Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35509a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader('d:/personal-git/Langchain-Learning/dummy-data.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf7a122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get embedding engine ready\n",
    "embeddings = OpenAIEmbeddings()\n",
    "#Embedd your texts\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "#Init your retriever\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2d3a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"What are generics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce657744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generics\n",
      "Main article: Generics in Java\n",
      "\n",
      "Generics\n",
      "Scripting/Compiler\n",
      "Functional programming (Lambda, Streaming)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([x.page_content[:200] for x in docs[:2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088660b5",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbf575a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = embeddings.embed_documents([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0458154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 301 embeddings\n",
      "Here's a sample of one: [0.003983437510569549, -0.008915782819376916, -0.01288274569942308]\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(embedding_list)} embeddings\")\n",
    "print (f\"Here's a sample of one: {embedding_list[0][:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acba392",
   "metadata": {},
   "source": [
    "# Memory\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfe9850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_ai_message(\"hi!\")\n",
    "history.add_user_message(\"what is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3eb3fcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='hi!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='what is the capital of India?', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ebd1a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is New Delhi.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_response = chat(history.messages)\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6681c69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='hi!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='what is the capital of India?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The capital of India is New Delhi.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.add_ai_message(ai_response.content)\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eab844b",
   "metadata": {},
   "source": [
    "# Chains\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9763ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952f9c5",
   "metadata": {},
   "source": [
    "### Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4ba1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "\n",
    "#Location Chain\n",
    "location_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f47fdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "\n",
    "# Holds my 'meal' chain\n",
    "meal_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5d8b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c58ccf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mOne classic dish from Mumbai is pav bhaji. It is a spicy vegetable curry, served with a soft round bread roll called pav.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "Pav Bhaji Recipe\n",
      "\n",
      "Ingredients:\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 teaspoon cumin seeds\n",
      "- 1 teaspoon mustard seeds\n",
      "- 2 onions, chopped\n",
      "- 3 cloves garlic, finely chopped\n",
      "- 1 teaspoon ground ginger\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon garam masala\n",
      "- 1 small green chilli, chopped\n",
      "- 1 large potato, peeled and cubed\n",
      "- 2 cups diced tomatoes \n",
      "- 2 cups cooked mixed vegetables, such as cauliflower, carrots, green beans, potatoes, etc.\n",
      "- 2 tablespoons tomato paste\n",
      "- 1 teaspoon chilli powder\n",
      "- 2 tablespoons butter\n",
      "- Fresh coriander leaves, finely chopped\n",
      "\n",
      "Method : \n",
      "1. Heat the oil in a large pan. Add the cumin and mustard seeds, and fry until they start to pop.\n",
      "2. Add the onions and garlic, and fry until golden.\n",
      "3. Add the ginger, coriander, garam masala and chilli, and fry for a minute.\n",
      "4. Add the potatoes, tomatoes, cooked vegetables, tomato paste and chilli powder. Stir to combine and cook until the potatoes are cooked through.\n",
      "5. Add the butter and stir to combine.\n",
      "6\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = overall_chain.run(\"Mumbai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c0d9a",
   "metadata": {},
   "source": [
    "## Summarization Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a98038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader('d:/personal-git/Langchain-Learning/dummy-data.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "#Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)\n",
    "#Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12ee6854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0ba9362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible. It is a general-purpose programming language intended to let programmers write once, run anywhere (WORA),[17] meaning that compiled Java code can run on all platforms that support Java without the need to recompile.[18] Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of the underlying computer architecture. The syntax of Java is similar to C and C++, but has fewer low-level facilities than either of them. The Java runtime provides dynamic capabilities (such as reflection and runtime code\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"capabilities (such as reflection and runtime code modification) that are typically not available in traditional compiled languages. As of 2019, Java was one of the most popular programming languages in use according to GitHub,[citation not found][19][20] particularly for clientâ€“server web applications, with a reported 9 million developers.[21]\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Java was originally developed by James Gosling at Sun Microsystems. It was released in May 1995 as a core component of Sun Microsystems' Java platform. The original and reference implementation Java compilers, virtual machines, and class libraries were originally released by Sun under proprietary licenses. As of May 2007, in compliance with the specifications of the Java Community Process, Sun had relicensed most of its Java technologies under the GPL-2.0-only license. Oracle offers its own HotSpot Java Virtual Machine, however the official reference implementation is the OpenJDK JVM which is free open-source software and used by most developers and is the default JVM for almost all Linux\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" Java is a high-level, class-based, object-oriented programming language that enables code to be written once and run anywhere. It has a syntax similar to C and C++, but fewer low-level features. The Java runtime also provides dynamic capabilities like reflection and runtime code.\n",
      "\n",
      " Java is one of the most popular programming languages in 2019, especially for web applications, with over 9 million developers. It possess capabilities not present in traditional compiled languages such as reflection and runtime code modification.\n",
      "\n",
      "\n",
      "Java was originally developed by Sun Microsystems, and released in 1995 as part of their Java platform. The compilers, virtual machines, and class libraries were initially released under private licenses. In 2007, most of these technologies were licensed under GPL-2.0-only. Oracle offers the HotSpot JVM, but the OpenJDK JVM is free, open-source, and used by most developers and is the default JVM for Linux.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Java is a popular, high-level programming language that is object-oriented and class-based, with syntax similarities to C and C++. It has dynamic capabilities, including reflection and runtime code modification, making it a favored choice for web applications. The Java platform and its underlying technologies were originally released under private licenses and later released under GPL-2.0-only. The OpenJDK JVM is free and open-source, and is the default for Linux.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
    "chain.run(texts[0:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
