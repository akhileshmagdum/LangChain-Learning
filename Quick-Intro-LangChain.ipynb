{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851ec1dd",
   "metadata": {},
   "source": [
    "**<h1 style=\"text-align: center;\">Quick Intro to LangChain</h1><hr>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d187e",
   "metadata": {},
   "source": [
    "## Setup OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528c1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'D:/personal-git')\n",
    "from key_api import apiKey\n",
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = apiKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed358c1a",
   "metadata": {},
   "source": [
    "## Install necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d9f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.135)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.4.48)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.25.0)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: OpenAI in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from OpenAI) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from OpenAI) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from OpenAI) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->OpenAI) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->OpenAI) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->OpenAI) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->OpenAI) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->OpenAI) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->OpenAI) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->OpenAI) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->OpenAI) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->OpenAI) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->OpenAI) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->OpenAI) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install langchain\n",
    "!python -m pip install OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e0e29",
   "metadata": {},
   "source": [
    "## Basic LLM demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4673a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "GPT (Generative Pre-trained Transformer) is a type of language model developed by OpenAI that uses deep learning to produce human-like text. It is a type of artificial intelligence (AI) that can generate natural language from a prompt. GPT can be used for a variety of tasks, including summarizing text, generating text from incomplete input, and answering questions. GPT models are trained on a large corpus of text, such as books, news articles, and Wikipedia pages, and are able to generate text that is indistinguishable from human-written text. GPT models are used in natural language processing (NLP) applications such as chatbots, question answering, and automatic translation.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6) #Temperature - The scale of creativeness a model can have (range 0 to 1)\n",
    "answer = llm(\"Explain what GPT is like I am a undergrad average computer science student\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc13a0",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e630910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number: 144\n",
      "What is the square root of 144\n",
      "\n",
      "\n",
      "The square root of 144 is 12.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "squareRootPrompt = PromptTemplate(\n",
    "    input_variables = ['number'],\n",
    "    template = \"What is the square root of {number}\"\n",
    ")\n",
    "\n",
    "generatedSqRootPrompt = squareRootPrompt.format(number = input(\"Enter number: \"))\n",
    "print(generatedSqRootPrompt)\n",
    "print(llm(generatedSqRootPrompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b349af",
   "metadata": {},
   "source": [
    "## LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5882142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a number: 144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe square root of 144 is 12.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "sqRootChain = LLMChain(llm=llm, prompt=squareRootPrompt)\n",
    "sqRootChain.run(input(\"Enter a number: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed77215",
   "metadata": {},
   "source": [
    "### Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2627e6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter cuisine for the restaurant: Indian\n",
      "\n",
      "\n",
      "Appetizers\n",
      "- Vegetable Samosas \n",
      "- Onion Bhajis\n",
      "- Paneer Tikka\n",
      "\n",
      "Main Course\n",
      "- Chicken Tikka Masala \n",
      "- Vegetable Korma\n",
      "- Lamb Rogan Josh\n",
      "- Paneer Makhani\n",
      "\n",
      "Desserts\n",
      "- Gulab Jamun\n",
      "- Rasmalai\n",
      "- Kheer\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "hotelNamePrompt = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"A fancy name for a {cuisine} food restaurant\"\n",
    ")\n",
    "\n",
    "hotelNameChain = LLMChain(llm=llm, prompt=hotelNamePrompt)\n",
    "\n",
    "hotelMenuPrompt = PromptTemplate(\n",
    "    input_variables=['name'], \n",
    "    template=\"Create a menu for {name}\"\n",
    ")\n",
    "\n",
    "hotelMenuChain = LLMChain(llm=llm, prompt=hotelMenuPrompt)\n",
    "\n",
    "#Here the sequence of the chains matter\n",
    "hotelChain = SimpleSequentialChain(chains=[hotelNameChain, hotelMenuChain])\n",
    "answer = hotelChain.run(input(\"Enter cuisine for the restaurant: \"))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a5320",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a0d47ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Mexican',\n",
       " 'hotelName': '\\n\\nTaco Palacio Azul',\n",
       " 'menuItems': '\\n\\n1. Quesadilla Combo - A flour tortilla filled with cheese, served with Mexican rice and refried beans. \\n\\n2. Mexican Salad - Mixed greens, grilled peppers, onions, and tomatoes, topped with shredded cheese, avocado, and sour cream. \\n\\n3. Fajita Platter - Grilled chicken or steak, onions, bell peppers, served with Mexican rice, refried beans and flour tortillas. \\n\\n4. Chilaquiles - Crispy corn tortillas topped with your choice of chorizo sausage, chicken, or steak, served with refried beans, Mexican rice, and guacamole. \\n\\n5. Carne Asada - Tender flank steak, cooked to perfection and served with Mexican rice, refried beans, and flour tortillas. \\n\\n6. Chicken Tortilla Soup - Chicken broth simmered with vegetables and topped with crispy strips of tortilla chips. \\n\\n7. Queso Fundido - melted cheese, chorizo, and peppers served with tortilla chips. \\n\\n8. Fish Tacos - Crispy battered cod served in soft flour tortillas with cabbage, onion, and tomatillo salsa. \\n\\n9'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=0.8)\n",
    "\n",
    "hotelNamePrompt = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"Suggest a fancy name for a {cuisine} restaurant\");\n",
    "\n",
    "hotelNameChain = LLMChain(llm=llm, prompt=hotelNamePrompt, output_key=\"hotelName\")\n",
    "\n",
    "menuItemsPrompt = PromptTemplate(\n",
    "                                input_variables=['hotelName'],\n",
    "                                template=\"Suggest some menus for {hotelName}\");\n",
    "menuChain = LLMChain(llm=llm, prompt=menuItemsPrompt, output_key=\"menuItems\")\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [hotelNameChain, menuChain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['hotelName', 'menuItems']\n",
    ")\n",
    "\n",
    "chain({'cuisine':'Mexican'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c9c27",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62089d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.5.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (pyproject.toml): started\n",
      "  Building wheel for wikipedia (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11706 sha256=c3badafd48cfa3c9d5a0c9f6a1b8757e96ee78bf557613909d295562eb45f17f\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\5e\\b6\\c5\\93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ceb3fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to investigate what langchain is.\n",
      "Action: Wikipedia\n",
      "Action Input: langchain\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: Sentence embedding\n",
      "Summary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vectors of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token preprended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \n",
      "Other approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \n",
      "An alternative direction is to aggregate word embeddings, such those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). Sentence embedding is a numeric representation of a sentence in the form of a vectors of real numbers, which encodes meaningful semantic information. It is often fine-tuned for use in sentence classification tasks. Other approaches to sentence embedding include aggregating word embeddings, such as Word2vec, into sentence embeddings through the use of approaches such as continuous bag-of-words (CBOW) or vector of locally aggregated word embeddings (VLAWE).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). Sentence embedding is a numeric representation of a sentence in the form of a vectors of real numbers, which encodes meaningful semantic information. It is often fine-tuned for use in sentence classification tasks. Other approaches to sentence embedding include aggregating word embeddings, such as Word2vec, into sentence embeddings through the use of approaches such as continuous bag-of-words (CBOW) or vector of locally aggregated word embeddings (VLAWE).'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, load_tools, initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True #Displays set by set internal execution\n",
    ")\n",
    "\n",
    "agent.run(\"What is langchain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a213bb",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8858a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Curry Palatial.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=hotelNamePrompt, memory=memory)\n",
    "print(chain.run(\"Indian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "639aa28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Red, White and Blue Bistro\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"American\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b32a718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Indian\n",
      "AI: \n",
      "\n",
      "Curry Palatial.\n",
      "Human: American\n",
      "AI: \n",
      "\n",
      "The Red, White and Blue Bistro\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d11743a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "convo = ConversationChain(llm=llm)\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc18b709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The capital of India is New Delhi. It is located in the northern part of the country and is the seat of the Indian government.\n",
      " The answer is 3.\n",
      "[HumanMessage(content='What is captial of India?', additional_kwargs={}), AIMessage(content=' The capital of India is New Delhi. It is located in the northern part of the country and is the seat of the Indian government.', additional_kwargs={}), HumanMessage(content='1+2', additional_kwargs={}), AIMessage(content=' The answer is 3.', additional_kwargs={})]\n",
      " Japan is an island country located in East Asia. It is the world's fourth-largest island country with an area of 377,972 square kilometers. It has a population of over 126 million people, making it the world's tenth-most populous country.\n",
      "[HumanMessage(content='What is captial of India?', additional_kwargs={}), AIMessage(content=' The capital of India is New Delhi. It is located in the northern part of the country and is the seat of the Indian government.', additional_kwargs={}), HumanMessage(content='1+2', additional_kwargs={}), AIMessage(content=' The answer is 3.', additional_kwargs={}), HumanMessage(content='Japan?', additional_kwargs={}), AIMessage(content=\" Japan is an island country located in East Asia. It is the world's fourth-largest island country with an area of 377,972 square kilometers. It has a population of over 126 million people, making it the world's tenth-most populous country.\", additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "chain = ConversationChain(llm=OpenAI(temperature=0.5), memory=ConversationBufferWindowMemory(k=1))\n",
    "\n",
    "print(chain.run(\"What is captial of India?\"))\n",
    "print(chain.run(\"1+2\"))\n",
    "print(chain.memory.buffer)\n",
    "print(chain.run(\"Japan?\"))\n",
    "print(chain.memory.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
